pr:
  branches:
    include:
      - master

trigger:
  branches:
    include:
      - master

stages:
  - stage: build_and_test
    displayName: ACN
    jobs:
      - job: setup
        displayName: Setup 
        pool:
          name: "$(BUILD_POOL_NAME_DEFAULT)"
        steps:
          - script: |
              BUILD_NUMBER=$(Build.BuildNumber)
              echo "##vso[task.setvariable variable=StorageID;isOutput=true]$(echo ${BUILD_NUMBER//./-})"
              echo "##vso[task.setvariable variable=Tag;isOutput=true]$(git describe --tags --always --dirty)"
              echo "##vso[task.setvariable variable=ImageTag;isOutput=true]$(git describe --tags --always --dirty)-test"
              sudo chown -R $(whoami):$(whoami) .
              go version
              go env
              which go
              echo $PATH
            name: "EnvironmentalVariables"
            displayName: "Set environmental variables"
            condition: always()

      - job: build
        displayName: Build Binaries
        dependsOn:
          - "setup"
        variables:
          TAG: $[ dependencies.setup.outputs['EnvironmentalVariables.Tag'] ]
          STORAGE_ID: $[ dependencies.setup.outputs['EnvironmentalVariables.StorageID'] ]
        pool:
          name: "$(BUILD_POOL_NAME_DEFAULT)"
        steps:
          - script: |
              make all-binaries-platforms VERSION=$(TAG)
            name: "BuildAllPlatformBinaries"
            displayName: "Build all platform binaries"

          - script: |
              mkdir -p ./output/bins
              cd ./output
              find . -name '*.tgz' -print -exec mv -t ./bins/ {} +
              find . -name '*.zip' -print -exec mv -t ./bins/ {} +
              shopt -s extglob
              rm -rf !("bins")
            name: "PrepareArtifacts"
            displayName: "Prepare Artifacts"

          - task: CopyFiles@2
            inputs:
              sourceFolder: "output"
              targetFolder: $(Build.ArtifactStagingDirectory)
            condition: succeeded()

          - task: PublishBuildArtifacts@1
            inputs:
              artifactName: "output"
              pathtoPublish: "$(Build.ArtifactStagingDirectory)"
            condition: succeeded()

          - task: AzureCLI@1
            inputs:
              azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
              scriptLocation: "inlineScript"
              inlineScript: |
                echo Creating storage container with name acn-$(STORAGE_ID) and account name $(STORAGE_ACCOUNT_NAME)
                az storage container create -n acn-$(STORAGE_ID) --account-name $(STORAGE_ACCOUNT_NAME) --public-access container
                az storage blob upload-batch -d acn-$(STORAGE_ID) -s ./output/bins/  --account-name $(STORAGE_ACCOUNT_NAME)
            displayName: Create artifact storage container
            condition: succeeded()

          - publish: ./test/apimodels/
            artifact: clusterdefinitions

      - job: build_images
        displayName: Build Images
        dependsOn:
          - "setup"
        variables:
          TAG: $[ dependencies.setup.outputs['EnvironmentalVariables.Tag'] ]
        pool:
          name: "$(BUILD_POOL_NAME_DEFAULT)"
        steps:
          - task: Docker@2
            displayName: Docker Login
            inputs:
              containerRegistry: $(ACR_SERVICE_CONNECTION)
              command: 'login'
              addPipelineData: false

          - script: |
              echo Tag is $(TAG)
              sudo make tools-images VERSION=$(TAG)
              docker run --privileged --rm tonistiigi/binfmt --install arm64
              make all-images VERSION=$(TAG)
            name: "BuildImages"
            displayName: "Build Images"

          - script: |
              wget https://github.com/aquasecurity/trivy/releases/download/v0.18.1/trivy_0.18.1_Linux-64bit.tar.gz
              tar -zxvf trivy*.tar.gz
              mkdir -p ./trivy-cache
              sudo ./trivy --exit-code 1 --cache-dir ./trivy-cache --severity HIGH,CRITICAL $IMAGE_REGISTRY/azure-npm:$(TAG) 
              sudo ./trivy --exit-code 1 --cache-dir ./trivy-cache --severity HIGH,CRITICAL $IMAGE_REGISTRY/azure-cns:$(TAG) 
              sudo ./trivy --exit-code 1 --cache-dir ./trivy-cache --severity HIGH,CRITICAL $IMAGE_REGISTRY/azure-cni-manager:$(TAG) 
            name: "TrivyScan"
            displayName: "Image Vulnerability Scan"

          - script: |
              docker tag $IMAGE_REGISTRY/azure-cni-manager:$(TAG) $IMAGE_REGISTRY/azure-cni-manager:$(TAG)-test
              docker push $IMAGE_REGISTRY/azure-cni-manager:$(TAG)-test

              function auto-retry()
              {
                  export i="1"
                  export attempts="300"
                  false
                  while [[ $? -ne 0 ]] && [[ $i -lt $attempts ]]; do
                    printf "Attempt $i/$attempts - " && "$@" && break ||  sleep 3 &&  i=$[$i+1] && false
                  done
              }

              auto-retry docker pull $IMAGE_REGISTRY/azure-npm:$(TAG)
              auto-retry docker pull $IMAGE_REGISTRY/azure-cns:$(TAG)
              auto-retry docker pull $IMAGE_REGISTRY/azure-cni-manager:$(TAG)-test
            name: "mcrreplication"
            displayName: "Push NPM Image and Wait for Repository"

          - task: Docker@2
            displayName: Docker Logout
            inputs:
              containerRegistry: $(ACR_SERVICE_CONNECTION)
              command: 'logout'
              addPipelineData: false

          - task: CopyFiles@2
            inputs:
              sourceFolder: "output"
              targetFolder: $(Build.ArtifactStagingDirectory)
            condition: succeeded()

          - task: PublishBuildArtifacts@1
            inputs:
              artifactName: "output"
              pathtoPublish: "$(Build.ArtifactStagingDirectory)"
            condition: succeeded()

      - job: test
        displayName: Run Tests
        dependsOn:
          - "setup"
        variables:
          STORAGE_ID: $[ dependencies.setup.outputs['EnvironmentalVariables.StorageID'] ]
        pool:
          name: "$(BUILD_POOL_NAME_DEFAULT)"
        steps:

          - script: |
              make tools
              # run test, echo exit status code to fd 3, pipe output from test to tee, which splits output to stdout and go-junit-report (which converts test output to report.xml), stdout from tee is redirected to fd 4. Take output written to fd 3 (which is the exit code of test), redirect to stdout, pipe to read from stdout then exit with that status code. Read all output from fd 4 (output from tee) and write to top stdout
              { { { { 
                    sudo -E env "PATH=$PATH" make test-all; 
                    echo $? >&3; 
                    } | tee >(build/tools/bin/go-junit-report > report.xml) >&4; 
                  } 3>&1; 
                } | { read xs; exit $xs; } 
              } 4>&1
            name: "Test"
            displayName: "Run Tests"

          - bash: |
              build/tools/bin/gocov convert coverage.out > coverage.json
              build/tools/bin/gocov-xml < coverage.json > coverage.xml
            name: "Coverage"
            displayName: "Generate Coverage Reports"
            condition: always()

          - task: PublishTestResults@2
            inputs:
              testRunner: JUnit
              testResultsFiles: report.xml
            displayName: "Publish Test Results"
            condition: always()

          - task: PublishCodeCoverageResults@1
            inputs:
              codeCoverageTool: Cobertura
              summaryFileLocation: coverage.xml
            displayName: "Publish Code Coverage Results"
            condition: always()

  #- template: singletenancy/aks-swift/e2e-job-template.yaml
  #  parameters:
  #    name: "aks_on_swift_e2e"
  #    displayName: AKS on Swift
  #    pipelineBuildImage: "$(BUILD_IMAGE)"

  - template: singletenancy/aks-engine/e2e-job-template.yaml
    parameters:
      name: "ubuntu_16_04_linux_e2e"
      displayName: Ubuntu 16.04
      pipelineBuildImage: "$(BUILD_IMAGE)"
      clusterDefinition: "cniLinux1604.json"
      clusterDefinitionCniTypeKey: "azureCNIURLLinux"
      clusterDefinitionCniBuildOS: "linux"
      clusterDefinitionCniBuildExt: ".tgz"

  - template: singletenancy/aks-engine/e2e-job-template.yaml
    parameters:
      name: "ubuntu_18_04_linux_e2e"
      displayName: Ubuntu 18.04
      pipelineBuildImage: "$(BUILD_IMAGE)"
      clusterDefinition: "cniLinux1804.json"
      clusterDefinitionCniTypeKey: "azureCNIURLLinux"
      clusterDefinitionCniBuildOS: "linux"
      clusterDefinitionCniBuildExt: ".tgz"

  - template: singletenancy/aks-engine/e2e-job-template.yaml
    parameters:
      name: "windows_19_03_e2e"
      displayName: "Windows 1903"
      pipelineBuildImage: "$(BUILD_IMAGE)"
      clusterDefinition: "cniWindows1903.json"
      clusterDefinitionCniTypeKey: "azureCNIURLWindows"
      clusterDefinitionCniBuildOS: "windows"
      clusterDefinitionCniBuildExt: ".zip"

  - stage: cleanup
    displayName: Cleanup
    dependsOn:
     # - "aks_on_swift_e2e"
      - "ubuntu_16_04_linux_e2e"
      - "ubuntu_18_04_linux_e2e"
      - "windows_19_03_e2e"
    jobs:
      - job: delete_remote_artifacts
        displayName: Delete remote artifacts
        pool:
          name: $(BUILD_POOL_NAME_DEFAULT)
          demands: agent.os -equals Linux
        steps:
          - checkout: none
          - task: AzureCLI@1
            inputs:
              azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
              scriptLocation: "inlineScript"
              inlineScript: |
                BUILD_NUMBER=$(Build.BuildNumber)
                BUILD_NUMBER=${BUILD_NUMBER//./-}
                echo Deleting storage container with name acn-$BUILD_NUMBER and account name $(STORAGE_ACCOUNT_NAME)
                az storage container delete -n acn-$BUILD_NUMBER --account-name $(STORAGE_ACCOUNT_NAME)
                echo Pruning old docker images...
                sudo docker system prune -f
            displayName: Cleanup remote Azure storage container
